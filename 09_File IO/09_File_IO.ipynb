{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing data. CSV formats\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. File IO Tools\n",
    "-------------------\n",
    "[Corey Schafer. File Objects - Reading and Writing to Files](https://www.youtube.com/watch?v=Uh2ebFW8OYM&t=515s)\n",
    "\n",
    "\n",
    "[File object](https://docs.python.org/3/glossary.html#term-file-object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `io` â€” core tools for working with streams\n",
    "\n",
    "* 3 main categories of IO: \n",
    "    - text IO \n",
    "    - binary IO \n",
    "    - raw IO.  \n",
    "* **file object** -- concrete object belonging to any of these categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "#### Text I/O\n",
    "* expects and produces `str` objects\n",
    "* the contents of the file are returned as:\n",
    "    - strings \n",
    "    - bytes having been first decoded (using a platform-dependent encoding or the specified encoding if given)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Built-in ``open()``](https://docs.python.org/3/library/functions.html?highlight=open#open)\n",
    " -- the easiest way to create a text stream \n",
    " \n",
    "```ipython\n",
    "open(file, mode='r', buffering=-1, encoding=None, errors=None, \n",
    "           newline=None, closefd=True, opener=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* open file and return **a stream**\n",
    "* raise IOError upon failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opening modes:\n",
    "* ```r``` -- open for reading (default)\n",
    "* ```w``` -- open for writing, truncating the file first\n",
    "* ```x``` -- create a new file and open it for writing (an `FileExistsError` if the file already exists)\n",
    "* ```+``` -- open a disk file for updating (reading and writing)\n",
    "* ```a``` -- open for writing, appending to the end of the file if it exists\n",
    "* ```b``` -- binary mode\n",
    "* ```t``` -- text mode (default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary I/O \n",
    "* **buffered I/O**, expects bytes-like objects and produces bytes objects\n",
    "* files opened in binary mode return contents as bytes objects\n",
    "* no encoding, decoding, or newline translation is performed  \n",
    "* streams can be used for all kinds of non-text data, and also when manual control over the handling of text data is desired\n",
    "\n",
    "#### Raw I/O \n",
    "* **unbuffered I/O**\n",
    "* is generally used as a low-level building-block for binary and text streams\n",
    "* it is rarely useful to directly manipulate a raw stream from user code\n",
    "* raw stream can be createed by opening a file in binary mode with **buffering** disabled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"IMAG1225.jpg\", \"rb\", buffering=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ABC\t          |Inherits\t| Stub Methods     |\tMixin Methods and Properties\n",
    ":---------| :---------| :------------------|:-----------------------------------\n",
    "`IOBase\t`      | \t    |`fileno, seek, truncate`\t| `close`, `closed`, `__enter__`, `__exit__`, `flush, isatty,` `__iter__`, `__next__`,` readable, readline,` `readlines, seekable,` `tell, writable, and writelines`\n",
    "`RawIOBase`\t  |`IOBase`\t|`readinto,  write`|Inherited `IOBase` methods,` read, and readall`\n",
    "`BufferedIOBase`|\t`IOBase`\t|`detach, read, read1, write`\t|Inherited `IOBase` methods, `readinto, and readinto1`\n",
    "`TextIOBase`\t|`IOBase`\t|`detach, read, readline,  write`\t|Inherited `IOBase` methods, `encoding, errors, and newlines`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to use a string or bytearray as a file for both reading and writing:\n",
    "* ```StringIO``` for string (in a text mode)\n",
    "* ```BytesIO``` for bytes (in a binary mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open(\"test.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'{type(f)}\\n {f.name}\\n { f.mode}')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading Files\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * #### ``f.read()`` -- reading Small Files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.txt\", \"r\") as f:\n",
    "    f_contents = f.read()\n",
    "    print(f'{type(f_contents)}\\n{f_contents}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * ####    ``f.readlines()`` -- reading Big Files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.txt\", \"r\") as f:\n",
    "    f_contents = f.readlines()\n",
    "    print(f'{type(f_contents)}\\n{f_contents}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_contents[3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.txt\", \"r\") as f:\n",
    "    f_contents = f.readlines(30)\n",
    "    print(f_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * #### ``f.readline()`` -- with extra lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.txt\", \"r\") as f:\n",
    "    f_contents = f.readline()\n",
    "    print(f_contents)\n",
    "    f_contents = f.readline()\n",
    "    print(f_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Print out without the extra lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.txt\", \"r\") as f:\n",
    "    f_contents = f.readline()\n",
    "    print(f_contents, end = '')\n",
    "    f_contents = f.readline()\n",
    "    print(f_contents, end = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Iterating through the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        print(line, end = '')\n",
    "    else: print('\\n', type(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Iterating through small chunks, with ```size_to_read``` characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.txt\", \"r\") as f:\n",
    "    size_to_read = 100\n",
    "    \n",
    "    f_contents = f.read(size_to_read)\n",
    "    print(len(f_contents))\n",
    "    print(f_contents, end = '')\n",
    "\n",
    "    f_contents = f.read(size_to_read)\n",
    "    print(len(f_contents))\n",
    "    print(f_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.txt\", \"r\") as f:\n",
    "    size_to_read = 10\n",
    "    f_contents = f.read(size_to_read)\n",
    "    print(f_contents, end = '')\n",
    "\n",
    "    f.seek(0)\n",
    "    \n",
    "    f_contents = f.read(size_to_read)\n",
    "    print(f_contents)\n",
    "    \n",
    "    print(f'Current position={f.tell()}')\n",
    "    while len(f_contents) > 0:\n",
    "        print(f_contents, end = '*')\n",
    "        f_contents = f.read(size_to_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Writing Files\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"test123456.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test2.txt\", \"w\") as f:\n",
    "    f.write(\"Test\")\n",
    "    f.seek(1)\n",
    "    f.write(\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Copying Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.txt\", \"r\") as rf:\n",
    "    with open(\"test_copy.txt\", \"w\") as wf:\n",
    "        for line in rf:\n",
    "            wf.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Copying the image without chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_counter=0\n",
    "with open(\"IMAG1225.jpg\", \"rb\") as rf:\n",
    "    with open(\"spring_2017.jpg\", \"wb\") as wf:\n",
    "        for line in rf:\n",
    "            wf.write(line)\n",
    "            iter_counter+=1\n",
    "            if iter_counter==1:\n",
    "                print(type(line))\n",
    "        \n",
    "iter_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Copying the image with chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_counter=0\n",
    "print(type(iter_counter))\n",
    "with open(\"IMAG1225.jpg\", \"rb\") as rf:\n",
    "    with open(\"spring_2018.jpg\", \"wb\") as wf:\n",
    "        chunk_size=1024\n",
    "        rf_chunk=rf.read(chunk_size)\n",
    "        while len(rf_chunk)>0:\n",
    "            wf.write(rf_chunk)\n",
    "            rf_chunk=rf.read(chunk_size)\n",
    "            iter_counter+=1\n",
    "iter_counter            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Working with CSV Files\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Description of CSV format \n",
    "\n",
    "1.  Each record is located on a separate line, delimited by a **line break** (CRLF):\n",
    "\n",
    "       aaa,bbb,ccc CRLF\n",
    "       \n",
    "       zzz,yyy,xxx CRLF\n",
    "\n",
    "2.  The last record in the file may or may not have an ending line break:\n",
    "\n",
    "       aaa,bbb,ccc CRLF\n",
    "       \n",
    "       zzz,yyy,xxx\n",
    "\n",
    "3.  In general, the **default** separator character (a delimiter) is  comma. Other popular delimiters include  tab (\\t), colon (:) and semi-colon (;) . \n",
    "\n",
    "    Properly parsing a CSV file requires us to know which delimiter is being used.\n",
    "\n",
    "4.  There maybe an optional header line appearing as the first line of the file with the same format as normal record lines. This header will contain names corresponding to the fields in the file        and should contain the same number of fields as the records in the rest of the file:\n",
    "\n",
    "       field_name,field_name,field_name CRLF\n",
    "       \n",
    "       aaa,bbb,ccc CRLF\n",
    "       \n",
    "       zzz,yyy,xxx CRLF\n",
    "\n",
    "5.  Each field may or may not be enclosed in double quotes:\n",
    "\n",
    "       \"aaa\",\"bbb\",\"ccc\" CRLF\n",
    "       zzz,yyy,xxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* that seems to be followed by most implementations\n",
    "* programmers can also define their own special-purpose CSV formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### ```csv``` module\n",
    "   * The ```csv``` moduleâ€™s ```reader``` and ```writer``` objects read and write sequences \n",
    "   * Programmers can also read and write data in dictionary form using the ```DictReader``` and ```DictWriter``` classes\n",
    "\n",
    "[CSV File Reading and Writing](https://docs.python.org/3/library/csv.html)\n",
    "\n",
    "[ CSV Module - How to Read, Parse, and Write CSV Files](https://www.youtube.com/watch?v=q5uM4VKywbA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### ``csv.reader`` reader object \n",
    "\n",
    "```ipython\n",
    "csv.reader(csvfile, dialect='excel', **fmtparams)\n",
    "```\n",
    "\n",
    "   - is responsible for reading and parsing tabular data in CSV format\n",
    "   - return a reader object which will iterate over **lines** in the given ```csvfile```\n",
    "   - ```csvfile``` can be any object which supports the iterator protocol and returns a string each time its ```__next__()``` method is called â€” file objects and list objects are both suitable\n",
    "   - an optional dialect parameter can be given which is used to define a set of parameters specific to a particular CSV dialect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('names.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    print(f'\"type of csv_file: \"{type(csv_file)}, \"type of csv_reader: \"{type(csv_reader)}')\n",
    "    \n",
    "    for line in csv_reader:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('names.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    \n",
    "    next(csv_reader) #to skip over the field name headers\n",
    "    for line in csv_reader:\n",
    "        print(line[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### ```csv.writer``` writer object \n",
    "\n",
    "```ipython\n",
    "csv.writer(csvfile, dialect='excel', **fmtparams)\n",
    "```\n",
    "\n",
    "- is responsible for writing tabular data in CSV format\n",
    "- return a writer object responsible for converting the userâ€™s data into delimited strings on the given file-like object\n",
    "- ```csvfile``` can be any object with a ```write()``` method \n",
    "- if ```csvfile``` is a file object, it should be opened with ```newline=''```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('names.csv',  'r', newline='') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    \n",
    "    with open('names_copy.csv', 'w', newline='') as new_file:\n",
    "        csv_writer = csv.writer(new_file, delimiter='-') \n",
    "\n",
    "        for line in csv_reader:\n",
    "            csv_writer.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('names.csv',  'r', newline='') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    \n",
    "    with open('new_names.csv', 'w', newline='') as new_file:\n",
    "        csv_writer = csv.writer(new_file, delimiter='\\t') \n",
    "\n",
    "        for line in csv_reader:\n",
    "            csv_writer.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new_names.csv', 'r', newline='') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)# default delimiter=',' but in this case delimiter='\\t'\n",
    "    for line in csv_reader:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new_names.csv', 'r', newline='') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter='\\t')# setup true delimeter\n",
    "    for line in csv_reader:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### DictReader & DictWriter\n",
    "\n",
    "```ipython \n",
    "class csv.DictReader(f, fieldnames=None, restkey=None, restval=None, dialect='excel', *args, **kwds)\n",
    "```\n",
    "     \n",
    "- create an object that operates like a regular reader but maps the information in each row to an ```OrderedDict``` whose keys are given by the optional **fieldnames** parameter\n",
    "-  ```fieldnames```  is a sequence. If ```fieldnames``` is omitted, the values in the first row of file ```f``` will be used as the fieldnames. Regardless of how the fieldnames are determined, the ordered dictionary preserves their original ordering\n",
    "- If a row has more fields than fieldnames, the remaining data is put in a list and stored with the fieldname specified by ```restkey```. If a non-blank row has fewer fields than fieldnames, the missing values are filled-in with ```None```\n",
    "     - Key access to the values in the row  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('names.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    #first line no longer contains fieldnames\n",
    "\n",
    "    for line in csv_reader: \n",
    "         print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('names.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "\n",
    "    for line in csv_reader: \n",
    "         print(line['email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('names.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    \n",
    "    with open('new_names_1.csv', 'w') as new_file:\n",
    "        fieldnames = ['first_name', 'last_name', 'email']\n",
    "\n",
    "        #csv_writer = csv.DictWriter(new_file, delimiter='\\t')#TypeError: __init__() missing 1 required positional argument: 'fieldnames'\n",
    "        csv_writer = csv.DictWriter(new_file, fieldnames=fieldnames, delimiter='\\t')\n",
    "\n",
    "        csv_writer.writeheader()\n",
    "\n",
    "        for line in csv_reader:\n",
    "            del line['email']\n",
    "            csv_writer.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('names.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    \n",
    "    with open('new_names_1.csv', 'w') as new_file:\n",
    "        fieldnames = ['first_name', 'last_name']#correct header\n",
    "\n",
    "        csv_writer = csv.DictWriter(new_file, fieldnames=fieldnames, delimiter='\\t')\n",
    "\n",
    "        csv_writer.writeheader()\n",
    "\n",
    "        for line in csv_reader:\n",
    "            del line['email']\n",
    "            csv_writer.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
